{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "requested-iceland",
   "metadata": {},
   "source": [
    "# Logistic Regression From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-spine",
   "metadata": {},
   "source": [
    "**NOTE:** If you would simply like to test out the code, just run `$python3 logistic_regression.py` in your terminal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-sudan",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Logistic Regression Hypothesis \n",
    "2. Loss Function & Intro to Negative Log-Likelihood (NLL)\n",
    "3. Gradient Descent for NLL\n",
    "4. Implimentation\n",
    "\n",
    "<br />\n",
    "\n",
    "---\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "Logistic Regression, though given the name, is a form of classification. Given the hypothesis $ w^{\\top}x+b $ logistic regression makes use of the sigmoid non-linear activation function which maps inputs in the range $ (0, 1)$. Intuitivly this is to be thought as a probability of how right the classifier thinks it classified a point correctly or incorrectly. This sigmoid function is often denoted $\\sigma(z)$ where $z = w^{\\top}x+b $. Specifically, this sigmoid function is:\n",
    "\n",
    "<br />\n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-(w^{\\top}x+b)}} $$\n",
    "\n",
    "<br />\n",
    "\n",
    "\n",
    "For added intuition, plotting the sigmoid function gives: \n",
    "\n",
    "<img src=\"./logistic_regression/img/sigmoid_function.png\" width=\"400\" height=\"200\">\n",
    "\n",
    "Now the Logistic Regression would make the hypothesis:\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "$$\n",
    "h(x ; w, b)=\\left\\{\\begin{array}{ll}\n",
    "1 & \\text { if } \\sigma(w^{\\top}x+b)>=0.5 \\\\\n",
    "0 & \\text { if } \\sigma(w^{\\top}x+b) < 0.5 \\\\\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "<br />\n",
    "\n",
    "---\n",
    "\n",
    "## Loss Function - Negative Log-Likelihood (NLL)\n",
    "\n",
    "Because the values are between 0 and 1 then we can think of a result given for some $x_i$ is the probability that the classifier believes it's either positive or negative. That is a guess on $x_i$ is $g_i = \\sigma(w^{\\top}x_i+b)$ where the probability $P(x)$ that a point is either negative or positive is $g_i$ if $y_i = 1$ and is $ 1 - g_i $ if $y_i = 0$. Using the laws of probability we can summarize this as:\n",
    "\n",
    "$$ \\prod_{i=1}^{n}\\left\\{\\begin{array}{ll}\n",
    "g_i & \\text { if } y_i = 1 \\\\\n",
    "1 - g_i & \\text { if } y_i = 0 \\\\\n",
    "\\end{array}\\right. $$\n",
    "\n",
    "Using a very beautiful trick we can rewrite this entire thing as:\n",
    "\n",
    "<br />\n",
    "\n",
    "$$ \\prod_{i=1}^{n} \\; g_i^{y_i} \\; (1-g_i)^{1-y_i} $$\n",
    "\n",
    "<br />\n",
    "\n",
    "But, in math we like summations and not big products like this. So to convert this to a sum we just use the log trick. Giving:\n",
    "\n",
    "<br />\n",
    "\n",
    "$$ \\sum_{i=1}^{n} \\; [y_i\\log(g_i) \\;+\\; (1-y_i)\\log(1-g_i)] $$\n",
    "\n",
    "<br />\n",
    "\n",
    "And this is out loss function. It is commonly known as the negative log-likelihood or log loss or cross entropy. The notation I will use for this loss funtion will be $\\mathbb{L}_{NLL}(g_i, y_i) $.\n",
    "\n",
    "Now that we have defined the loss, we can write our normalized objective function $J(w, b)$ for logistic regression as:\n",
    "\n",
    "<br />\n",
    "\n",
    "$$ J(w, b) = \\frac{1}{n} \\sum_{i=1}^{n} [\\mathbb{L}_{NLL}(\\sigma(w^{\\top}x_i+b), y_i)] + \\frac{\\lambda}{2} \\|w\\|^{2} $$\n",
    "\n",
    "<br />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "The typical gradient descent form for our weights and bias is as follows:\n",
    "\n",
    "<br />\n",
    "\n",
    "$$ w: \\;\\; w_{t+1} = w_{t} - \\mu \\nabla_{w}J(w, b) $$\n",
    "\n",
    "<br />\n",
    "\n",
    "$$ b: \\;\\; w_{t+1} = b_{t} - \\mu \\nabla_{b}J(w, b) $$\n",
    "\n",
    "<br />\n",
    "\n",
    "I am going to omit the proof but the derivative of our loss w.r.t. our weights are $ (\\sigma(w^{\\top}x_i+b) - y_i)x_i $ where $ \\sigma(w^{\\top}x_i+b) $ is our hypothesis, so this can simply be rewriten as: $ (h_i - y_i)x_i $. Similarly the update for our bias term can be written as:  $ (h_i - y_i) $. This leads to the following equation:\n",
    "\n",
    "<br />\n",
    "\n",
    "$$ w: \\;\\; w_{t+1} = w_{t} - \\mu (\\frac{1}{n} \\sum_{i=1}^{n} [(\\sigma(w^{\\top}x_i+b) - y_i)x_i] + \\lambda \\|w\\|)$$\n",
    "\n",
    "<br />\n",
    "\n",
    "$$ b: \\;\\; w_{t+1} = b_{t} - \\mu (\\frac{1}{n} \\sum_{i=1}^{n} [(\\sigma(w^{\\top}x_i+b) - y_i)] + \\lambda \\|w\\|) $$\n",
    "\n",
    "<br />\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## My Implimentation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "attached-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "floppy-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather Data\n",
    "n = 100\n",
    "X, y = make_blobs(n_samples = n, centers = 2, random_state = 12)\n",
    "\n",
    "y = y[:, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "gentle-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Activation Function\n",
    "def sigmoid(z): \n",
    "    return 1.0 / (1.0 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quiet-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the Model.\n",
    "\n",
    "class LogisticRegression:\n",
    "    def predict(self, X, w, b):\n",
    "        return sigmoid(X.dot(w) + b)\n",
    "\n",
    "    def loss(self, pred, y):\n",
    "        \"\"\"\n",
    "        This is a numerically stable way to compute the loss. That is\n",
    "        why it looks wierd. If you don't do this you will likely end up\n",
    "        getting overflows.\n",
    "        \n",
    "        \"\"\"\n",
    "        NLL = (y * np.log(pred + 1e-6) + (1 - y) * np.log(1 - pred + 1e-6)) \n",
    "        return -np.sum(NLL) * (1.0 / self.m)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        eta = 0.01\n",
    "        epochs = 5000\n",
    "\n",
    "        self.m, self.n = X.shape\n",
    "\n",
    "        # Declare the Weights\n",
    "        self.weights = np.random.uniform(-1, 1, (self.n, 1))\n",
    "        self.bias = np.random.uniform(-1, 1, (1, 1))\n",
    "\n",
    "        for i in range(epochs):\n",
    "            predicted = self.predict(X, self.weights, self.bias)\n",
    "\n",
    "            # Show the loss every 500th epoch\n",
    "            if i % 500 == 0: print(\"Loss on step {} is: {}\".format(i, self.loss(predicted, y)))\n",
    "\n",
    "            self.weights = self.weights - eta * X.T.dot(predicted - y)\n",
    "            self.bias = self.bias - eta * np.sum(predicted - y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "stuffed-reality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on step 0 is: 0.4459884197619967\n",
      "Loss on step 500 is: 0.03562543561883667\n",
      "Loss on step 1000 is: 0.02056306128077044\n",
      "Loss on step 1500 is: 0.014915202660124357\n",
      "Loss on step 2000 is: 0.011888555767224581\n",
      "Loss on step 2500 is: 0.009974829294183099\n",
      "Loss on step 3000 is: 0.008643202944225777\n",
      "Loss on step 3500 is: 0.0076568411726937674\n",
      "Loss on step 4000 is: 0.00689332071079478\n",
      "Loss on step 4500 is: 0.00628263891582526\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and Fit the Model \n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Grab the Weights and Bias\n",
    "weight0, weight1 = model.weights\n",
    "bias = model.bias[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "direct-deficit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot \n",
    "\n",
    "for i in range(n):\n",
    "    if (y[i] == 1):\n",
    "        plt.scatter(X[:, 0][i], X[:, 1][i], color=\"green\") \n",
    "    else:\n",
    "        plt.scatter(X[:, 0][i], X[:, 1][i], color=\"blue\")\n",
    "        \n",
    "x = np.linspace(-10, 10, 10)\n",
    "\n",
    "hyperplane = (-(weight0 / weight1) * x) - (bias / weight1)\n",
    "\n",
    "plt.suptitle(\"Logistic Regression\")\n",
    "\n",
    "plt.plot(x, hyperplane, '-', color = \"red\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-session",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
